{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-12T02:42:15.694791Z",
     "iopub.status.busy": "2025-03-12T02:42:15.694595Z",
     "iopub.status.idle": "2025-03-12T02:42:21.860880Z",
     "shell.execute_reply": "2025-03-12T02:42:21.860094Z",
     "shell.execute_reply.started": "2025-03-12T02:42:15.694773Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T02:42:21.862089Z",
     "iopub.status.busy": "2025-03-12T02:42:21.861652Z",
     "iopub.status.idle": "2025-03-12T02:42:25.465392Z",
     "shell.execute_reply": "2025-03-12T02:42:25.464508Z",
     "shell.execute_reply.started": "2025-03-12T02:42:21.862060Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855ec7d397794e1f96bd14f2a80ff9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset_infos.json:   0%|          | 0.00/960 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01252c8dd4e47b68560d8af75499c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-02f200ca5f2a7868.parquet:   0%|          | 0.00/2.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ee0d103ce64d8c859b4700274c13ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-405befbaa3bcf1a2.parquet:   0%|          | 0.00/276k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a9ac6487fc4aafbe3cb1b86464b92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-5372924f059fe767.parquet:   0%|          | 0.00/275k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9fa3c643794a21aad6bdbfa043bdfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/9600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2fe479e07d64b7db1e16b69966b88f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2501076cd6406fa1c917500a025eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(9600,\n",
       " ('选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般',\n",
       "  1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,split):\n",
    "        self.dataset=load_dataset(path='lansinuote/ChnSentiCorp', split=split)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        text=self.dataset[i]['text']\n",
    "        label=self.dataset[i]['label']\n",
    "\n",
    "        return text,label\n",
    "\n",
    "dataset=Dataset('train')\n",
    "len(dataset),dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 加载字典和分词工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T02:42:25.466400Z",
     "iopub.status.busy": "2025-03-12T02:42:25.466060Z",
     "iopub.status.idle": "2025-03-12T02:42:30.937844Z",
     "shell.execute_reply": "2025-03-12T02:42:30.937163Z",
     "shell.execute_reply.started": "2025-03-12T02:42:25.466380Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd930914785e400e94d3247c692f0cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e828a60240e45d4a12d9459655bdee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7112e26d7f4a3dbfc11c9a81fe0d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e93577f0834582b3e0d145a6592614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/269k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f888ee0338fa4d97a1e8ac9d2916af9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/624 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='bert-base-chinese', vocab_size=21128, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "token = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "\n",
    "token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T02:55:32.347390Z",
     "iopub.status.busy": "2025-03-12T02:55:32.347091Z",
     "iopub.status.idle": "2025-03-12T02:55:32.504685Z",
     "shell.execute_reply": "2025-03-12T02:55:32.503855Z",
     "shell.execute_reply.started": "2025-03-12T02:55:32.347365Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 500]),\n",
       " torch.Size([16, 500]),\n",
       " torch.Size([16, 500]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collate_fn(data):\n",
    "    sents=[i[0] for i in data]\n",
    "    labels=[i[1] for i in data]\n",
    "\n",
    "    #编码\n",
    "    data=token.batch_encode_plus(batch_text_or_text_pairs=sents,\n",
    "                                truncation=True,\n",
    "                                padding='max_length',\n",
    "                                max_length=500,\n",
    "                                return_tensors='pt',\n",
    "                                return_length=True,\n",
    "                                )\n",
    "\n",
    "    #input_ids:编码之后的数字\n",
    "    #attention_mask:是补零的位置是0,其他位置是1\n",
    "    input_ids=data['input_ids']\n",
    "    attention_mask = data['attention_mask']\n",
    "    token_type_ids = data['token_type_ids']\n",
    "\n",
    "    labels=torch.LongTensor(labels)\n",
    "\n",
    "    return input_ids, attention_mask, token_type_ids, labels\n",
    "\n",
    "#数据加载器\n",
    "loader=torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                  batch_size=16,\n",
    "                                  collate_fn=collate_fn,\n",
    "                                  shuffle=True,\n",
    "                                  drop_last=True)\n",
    "\n",
    "#取第一个批次的数据\n",
    "for i,(input_ids, attention_mask, token_type_ids, labels) in enumerate(loader):\n",
    "    break\n",
    "\n",
    "print(len(loader))\n",
    "input_ids.shape, attention_mask.shape, token_type_ids.shape, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T03:08:14.983608Z",
     "iopub.status.busy": "2025-03-12T03:08:14.983279Z",
     "iopub.status.idle": "2025-03-12T03:08:43.084455Z",
     "shell.execute_reply": "2025-03-12T03:08:43.083646Z",
     "shell.execute_reply.started": "2025-03-12T03:08:14.983582Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94db6e9be0894bb492d6caec05c67e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/412M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 500, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "#加载预训练模型\n",
    "pretrained=BertModel.from_pretrained('bert-base-chinese')\n",
    "#不训练,不需要计算梯度\n",
    "'''在训练过程中这些参数不会被更新。这样做的目的是使用预训练模型的特征提取能力，而不对其进行微调'''\n",
    "for param in pretrained.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "#模型试算\n",
    "out = pretrained(input_ids=input_ids,\n",
    "                 attention_mask=attention_mask,\n",
    "                 token_type_ids=token_type_ids)\n",
    "out.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 定义下游任务模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T03:11:50.019249Z",
     "iopub.status.busy": "2025-03-12T03:11:50.018938Z",
     "iopub.status.idle": "2025-03-12T03:12:00.369883Z",
     "shell.execute_reply": "2025-03-12T03:12:00.369025Z",
     "shell.execute_reply.started": "2025-03-12T03:11:50.019228Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc=torch.nn.Linear(768,2)\n",
    "\n",
    "    def forward(self,input_ids,attention_mask,token_type_ids):\n",
    "        with torch.no_grad(): #只需要进行特征提取而不需要更新模型参数\n",
    "            out = pretrained(input_ids=input_ids,\n",
    "                 attention_mask=attention_mask,\n",
    "                 token_type_ids=token_type_ids)\n",
    "\n",
    "        out=self.fc(out.last_hidden_state[:,0])\n",
    "        #将输入张量的每一行（即每个样本的输出）转换为一个概率分布，所有元素的和为1\n",
    "        out=out.softmax(dim=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "model=Model()\n",
    "\n",
    "model(input_ids=input_ids,\n",
    "      attention_mask=attention_mask,\n",
    "      token_type_ids=token_type_ids).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T03:17:06.086194Z",
     "iopub.status.busy": "2025-03-12T03:17:06.085905Z",
     "iopub.status.idle": "2025-03-12T04:08:56.965022Z",
     "shell.execute_reply": "2025-03-12T04:08:56.964119Z",
     "shell.execute_reply.started": "2025-03-12T03:17:06.086172Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7590072751045227 0.375\n",
      "5 0.6746047735214233 0.5625\n",
      "10 0.6309472918510437 0.6875\n",
      "15 0.6731126308441162 0.6875\n",
      "20 0.6028311848640442 0.75\n",
      "25 0.6080811619758606 0.625\n",
      "30 0.6647576689720154 0.5\n",
      "35 0.520226001739502 1.0\n",
      "40 0.5909832119941711 0.6875\n",
      "45 0.5008869171142578 0.9375\n",
      "50 0.4827878475189209 0.9375\n",
      "55 0.5563780069351196 0.875\n",
      "60 0.48446062207221985 0.875\n",
      "65 0.47542521357536316 0.875\n",
      "70 0.4827728569507599 0.9375\n",
      "75 0.49847108125686646 0.8125\n",
      "80 0.4473411440849304 0.875\n",
      "85 0.4774356186389923 0.875\n",
      "90 0.4438154101371765 0.9375\n",
      "95 0.43533143401145935 0.9375\n",
      "100 0.48415639996528625 0.875\n",
      "105 0.5001518726348877 0.75\n",
      "110 0.5333747863769531 0.75\n",
      "115 0.47413820028305054 0.875\n",
      "120 0.4978610575199127 0.875\n",
      "125 0.5136285424232483 0.875\n",
      "130 0.5017361640930176 0.8125\n",
      "135 0.48214778304100037 0.8125\n",
      "140 0.4277268052101135 0.9375\n",
      "145 0.5093130469322205 0.875\n",
      "150 0.4964030683040619 0.8125\n",
      "155 0.6243466138839722 0.6875\n",
      "160 0.48617786169052124 0.75\n",
      "165 0.4418548345565796 0.9375\n",
      "170 0.40361934900283813 0.9375\n",
      "175 0.466561883687973 0.875\n",
      "180 0.44522878527641296 0.875\n",
      "185 0.4148256182670593 0.9375\n",
      "190 0.5826003551483154 0.6875\n",
      "195 0.4371708631515503 0.875\n",
      "200 0.614971399307251 0.6875\n",
      "205 0.48233121633529663 0.875\n",
      "210 0.44358575344085693 0.875\n",
      "215 0.4014107584953308 0.9375\n",
      "220 0.38592472672462463 0.9375\n",
      "225 0.4202612638473511 0.875\n",
      "230 0.4111069440841675 0.9375\n",
      "235 0.5806137919425964 0.6875\n",
      "240 0.4398702383041382 0.875\n",
      "245 0.3996492624282837 1.0\n",
      "250 0.37827327847480774 1.0\n",
      "255 0.40103352069854736 1.0\n",
      "260 0.40860074758529663 0.875\n",
      "265 0.5136756300926208 0.8125\n",
      "270 0.39948800206184387 0.9375\n",
      "275 0.5737124681472778 0.6875\n",
      "280 0.6029447913169861 0.6875\n",
      "285 0.46900561451911926 0.875\n",
      "290 0.42558416724205017 0.9375\n",
      "295 0.4474238455295563 0.875\n",
      "300 0.5854877829551697 0.6875\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "optimizer=AdamW(model.parameters(),lr=5e-4)\n",
    "criterion=torch.nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "\n",
    "for i, (input_ids, attention_mask, token_type_ids,\n",
    "        labels) in enumerate(loader):\n",
    "    out = model(input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids)\n",
    "    \n",
    "    #计算损失\n",
    "    loss=criterion(out,labels)\n",
    "    #反向传播和优化\n",
    "    loss.backward()#计算损失的梯度\n",
    "    optimizer.step()#更新模型参数\n",
    "    optimizer.zero_grad()#清空优化器的梯度\n",
    "\n",
    "    #打印训练信息\n",
    "    if i%5==0:\n",
    "        out=out.argmax(dim=1) #找到每个样本预测结果中概率最大的类别索引\n",
    "        accuracy=(out==labels).sum().item()/len(labels)\n",
    "        #item() 方法用于将包含单个值的张量转换为 Python 标量\n",
    "        print(i,loss.item(),accuracy)\n",
    "    \n",
    "    #当处理到第 300 个批次时，终止训练循环\n",
    "    if i == 300:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:10:49.896838Z",
     "iopub.status.busy": "2025-03-12T04:10:49.896506Z",
     "iopub.status.idle": "2025-03-12T04:12:42.132162Z",
     "shell.execute_reply": "2025-03-12T04:12:42.131371Z",
     "shell.execute_reply.started": "2025-03-12T04:10:49.896811Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0.85625\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    correct=0\n",
    "    total=0\n",
    "    \n",
    "    loader_test=torch.utils.data.DataLoader(dataset=Dataset('validation'),\n",
    "                                  batch_size=32,\n",
    "                                  collate_fn=collate_fn,\n",
    "                                  shuffle=True,\n",
    "                                  drop_last=True)\n",
    "\n",
    "    for i, (input_ids, attention_mask, token_type_ids,labels) in enumerate(loader_test):\n",
    "        if i==5:\n",
    "            break\n",
    "        print(i)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(input_ids=input_ids,\n",
    "                 attention_mask=attention_mask,\n",
    "                 token_type_ids=token_type_ids)\n",
    "        out=out.argmax(dim=1)\n",
    "        correct+=(out==labels).sum().item()\n",
    "        total+=len(labels)\n",
    "\n",
    "    print(correct/total)\n",
    "        \n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
